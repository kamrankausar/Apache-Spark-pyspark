{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fa40c254390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To Check Sapark is working\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import OS for navigation file and folder.In Jupyter ls, dir, cd, pwd work well no need to import os \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/genius'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/genius'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading Uber Data\n",
    "uber = sc.textFile(\"uber_reduce.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dispatching_base_number,date,active_vehicles,trips'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See First Row\n",
    "uber.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_number,date,active_vehicles,trips',\n",
       " 'B02617,2/5/2015,1524,14499',\n",
       " 'B02682,2/5/2015,1418,13782',\n",
       " 'B02598,2/5/2015,1179,11609',\n",
       " 'B02512,2/5/2015,264,2022']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See some more rows\n",
    "uber.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count total number of rows\n",
    "uber.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do some cleaning on Data like remove first row and spliting save all in new RDD name uber_final\n",
    "uber_final = uber.filter(lambda row: \"date\" not in row).map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B02617', '2/5/2015', '1524', '14499'],\n",
       " ['B02682', '2/5/2015', '1418', '13782'],\n",
       " ['B02598', '2/5/2015', '1179', '11609'],\n",
       " ['B02512', '2/5/2015', '264', '2022'],\n",
       " ['B02765', '2/5/2015', '355', '3011']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_final.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After removing first row\n",
    "uber_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See type of uber and uber_final\n",
    "type(uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uber_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Want to reuse uber_final RDD use cache()\n",
    "uber_final.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B02617\n",
      "B02682\n",
      "B02598\n",
      "B02512\n",
      "B02765\n",
      "B02764\n",
      "B02617\n",
      "B02765\n",
      "B02598\n",
      "B02512\n",
      "B02764\n",
      "B02682\n",
      "B02598\n",
      "B02512\n",
      "B02617\n",
      "B02682\n",
      "B02764\n",
      "B02765\n",
      "B02764\n",
      "B02765\n",
      "B02598\n",
      "B02617\n",
      "B02682\n",
      "B02512\n",
      "B02617\n",
      "B02682\n",
      "B02598\n",
      "B02764\n",
      "B02512\n",
      "B02765\n",
      "B02764\n",
      "B02512\n",
      "B02617\n",
      "B02765\n",
      "B02682\n",
      "B02598\n",
      "B02617\n",
      "B02764\n",
      "B02512\n",
      "B02598\n",
      "B02765\n",
      "B02682\n",
      "B02617\n",
      "B02512\n",
      "B02682\n",
      "B02765\n",
      "B02598\n",
      "B02764\n",
      "B02617\n",
      "B02682\n",
      "B02764\n",
      "B02765\n",
      "B02512\n",
      "B02598\n",
      "B02764\n",
      "B02512\n",
      "B02598\n",
      "B02765\n",
      "B02617\n",
      "B02682\n",
      "B02682\n",
      "B02764\n",
      "B02617\n",
      "B02765\n",
      "B02512\n",
      "B02598\n",
      "B02598\n",
      "B02512\n",
      "B02617\n",
      "B02764\n",
      "B02682\n",
      "B02765\n",
      "B02764\n",
      "B02512\n",
      "B02682\n",
      "B02617\n",
      "B02598\n",
      "B02765\n",
      "B02598\n",
      "B02682\n",
      "B02617\n",
      "B02765\n",
      "B02764\n",
      "B02512\n",
      "B02598\n",
      "B02512\n",
      "B02682\n",
      "B02764\n",
      "B02765\n",
      "B02617\n",
      "B02764\n",
      "B02617\n",
      "B02598\n",
      "B02682\n",
      "B02765\n",
      "B02512\n",
      "B02598\n",
      "B02682\n",
      "B02765\n",
      "B02617\n",
      "B02512\n",
      "B02764\n",
      "B02512\n",
      "B02617\n",
      "B02682\n",
      "B02764\n"
     ]
    }
   ],
   "source": [
    "#To print first Column i.e dispatching_base_number of uber_final RDD\n",
    "for col in uber_final.take(uber_final.count()): print(col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display total number of distinct dispatching_base_number \n",
    "uber_final.map(lambda col: col[0]).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B02598', 'B02682', 'B02765', 'B02617', 'B02764', 'B02512']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display name of distinct dispatching_base_number\n",
    "uber_final.map(lambda col: col[0]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display total no of times dispatching_base_number - \"B02598\" occurs to do this we use filter()\n",
    "uber_final.filter(lambda row: \"B02598\" in row).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter and create new RDD \"baseB02598\"\n",
    "baseB02598 = uber_final.filter(lambda row: \"B02598\" in row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B02598', '2/5/2015', '1179', '11609'],\n",
       " ['B02598', '2/6/2015', '1181', '11897'],\n",
       " ['B02598', '2/7/2015', '1031', '10512'],\n",
       " ['B02598', '2/8/2015', '923', '8129'],\n",
       " ['B02598', '2/9/2015', '976', '8135']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 5 rows\n",
    "baseB02598.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count where trip of baseB02598 is greater than 10K\n",
    "baseB02598.filter(lambda col: int(col[3]) > 10000 ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B02598', '2/5/2015', '1179', '11609'],\n",
       " ['B02598', '2/6/2015', '1181', '11897'],\n",
       " ['B02598', '2/7/2015', '1031', '10512'],\n",
       " ['B02598', '2/11/2015', '1115', '10034'],\n",
       " ['B02598', '2/12/2015', '1181', '11640'],\n",
       " ['B02598', '2/13/2015', '1216', '13062'],\n",
       " ['B02598', '2/14/2015', '1111', '12678'],\n",
       " ['B02598', '2/15/2015', '1003', '11517'],\n",
       " ['B02598', '2/19/2015', '1127', '11739'],\n",
       " ['B02598', '2/20/2015', '1186', '12758'],\n",
       " ['B02598', '2/21/2015', '1044', '12132']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display where trip of baseB02598 is greater than 10K\n",
    "baseB02598.filter(lambda col: int(col[3]) > 10000).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B02598', 182613),\n",
       " ('B02682', 238722),\n",
       " ('B02765', 81875),\n",
       " ('B02617', 247329),\n",
       " ('B02764', 656110),\n",
       " ('B02512', 33136)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some trailer of Key,value pair \n",
    "#Display total number of trip of each Base\n",
    "uber_final.map(lambda kp: (kp[0],int(kp[3]))).reduceByKey(lambda k,v: k + v).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B02764', 656110),\n",
       " ('B02617', 247329),\n",
       " ('B02682', 238722),\n",
       " ('B02598', 182613),\n",
       " ('B02765', 81875)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 5 Busiest Base according to trip\n",
    "uber_final.map(lambda kp: (kp[0],int(kp[3]))).reduceByKey(lambda k,v: k + v).takeOrdered(5,key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some other concept like how to create own RDD by using parallelize()\n",
    "own_Rdd1 = sc.parallelize(range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(own_Rdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "own_Rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2], [3, 3, 3], [4, 4, 4]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map() vs flatmap(),faltmap() flaten the data set i.e remove hierarchy in data set which is in json data\n",
    "#map() on own RDD\n",
    "sc.parallelize([2,3,4]).map(lambda x:[x,x,x]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 3, 3, 3, 4, 4, 4]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatMap():- It is helpful when dealing with data set which has some hierarchy to it. Ultimately remove hierarchy\n",
    "sc.parallelize([2,3,4]).flatMap(lambda x: [x,x,x]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#To see default Parallelism by default two partitions on each Core\n",
    "print(sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some sets operation on RDD like combine, compare and distinct \n",
    "own_Rdd2 = sc.parallelize(range(5,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "own_Rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "own_Rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Union() operation, Union() take one argument  and repetition of elements allowed \n",
    "own_Rdd1.union(own_Rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 9, 6, 7]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intersection(),It display common elements in RDDs,syntax:- takes one Rdd as argument\n",
    "own_Rdd1.intersection(own_Rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 12, 4, 1, 13, 5, 9, 2, 14, 10, 6, 11, 3, 7]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display Distinct elements in Rdds\n",
    "own_Rdd1.union(own_Rdd2).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
